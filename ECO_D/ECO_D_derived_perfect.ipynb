{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import multiprocessing as mp\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "%load_ext memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9295\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "XTRA_FEAT   = 1 #masscart, masspole, length\n",
    "N_ACTIONS   = env.action_space.n\n",
    "N_STATES    = env.observation_space.shape[0]  +  XTRA_FEAT \n",
    "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     # to confirm the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  VBKG0BIX_18_32_50\n",
      "NN-MODEL FILENAME:  ./models/VBKG0BIX_18_32_50_NN.pt\n"
     ]
    }
   ],
   "source": [
    "RNDM_STRING = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8)) + datetime.now().strftime(\"_%H_%M_%S\")\n",
    "print(\"ID: \",RNDM_STRING)\n",
    "MODEL_FILENAME = './models/'+ RNDM_STRING + \"_NN\" + \".pt\"\n",
    "print(\"NN-MODEL FILENAME: \", MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndim_grid(start,stop, granularity):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.linspace(start[i],stop[i],granularity[i]) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(value, borders):\n",
    "    c_pos_val, c_vel_val, p_ang_val, p_vel_val, length_val   = value\n",
    "    c_pos_s  , c_vel_s  ,p_ang_s   , p_vel_s  , length_s     = borders\n",
    "    \n",
    "    indx = np.empty_like(value).astype(np.uint)\n",
    "    \n",
    "    for i in range(value.shape[0]):\n",
    "        if value[i] > borders[i].max():\n",
    "            indx[i] = borders[i].argmax()\n",
    "        else:\n",
    "            indx[i] = np.where(borders[i] >= value[i])[0][0].astype(np.uint)\n",
    "    return indx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NODES:  10\n",
      "Number of EPISODES per NODE 200\n"
     ]
    }
   ],
   "source": [
    "T_LR           = 1e-2\n",
    "T_GAMMA        = 0.99\n",
    "T_EPSILON      = 0.98\n",
    "\n",
    "NO_OF_NODES    = 10\n",
    "NO_OF_EPISODES = 200\n",
    "TIMESTEP_LIMIT = 200\n",
    "\n",
    "print(\"Number of NODES: \", NO_OF_NODES)\n",
    "print(\"Number of EPISODES per NODE\", NO_OF_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "HIDDEN_LAYER        = 50\n",
    "BATCH_SIZE          = 32\n",
    "NN_LR               = 1e-3  # learning rate\n",
    "NN_GAMMA            = 0.9   # reward discount\n",
    "TARGET_REPLACE_ITER = 100   # target update frequency\n",
    "TERMINAL_BIAS       = 0.5   # no. of terminal memories in batch\n",
    "MIN_MEMORY_CAP      = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ITERATIONS:  15\n"
     ]
    }
   ],
   "source": [
    "MAX_NO_OF_ITERATIONS = 15\n",
    "MAX_NN_ITERATIONS    = 7000\n",
    "print(\"Number of ITERATIONS: \",MAX_NO_OF_ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_prev(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_prev, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES - XTRA_FEAT, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.adv = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.adv.weight) \n",
    "    \n",
    "        self.val = nn.Linear(HIDDEN_LAYER, 1)\n",
    "        nn.init.xavier_uniform_(self.val.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        \n",
    "        return val + adv - adv.mean()\n",
    "    \n",
    "class D3QN_prev(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net  = Net_prev()\n",
    "\n",
    "\n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.data.numpy().astype(np.float16)\n",
    "        return actions_value\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.adv = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.adv.weight) \n",
    "    \n",
    "        self.val = nn.Linear(HIDDEN_LAYER, 1)\n",
    "        nn.init.xavier_uniform_(self.val.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        \n",
    "        return val + adv - adv.mean()\n",
    "    \n",
    "class D3QN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "\n",
    "        self.learn_step_counter  = 0 # for target updating\n",
    "        \n",
    "        self.good_memory_counter = 0 # for storing non-terminal memories\n",
    "        self.good_memory         = np.zeros((MIN_MEMORY_CAP ,N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.bad_memory_counter  = 0 # for storing terminal memories\n",
    "        self.bad_memory          = np.zeros((MIN_MEMORY_CAP , N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.optimizer           = torch.optim.Adam(self.eval_net.parameters(), lr=NN_LR)\n",
    "        self.loss_func           = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.data.numpy().astype(np.float16)\n",
    "        return actions_value\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        good_sample_index_limit = min(MIN_MEMORY_CAP, self.good_memory_counter)\n",
    "        bad_sample_index_limit = min(MIN_MEMORY_CAP, self.bad_memory_counter)\n",
    "\n",
    "        good_sample_index = np.random.choice(int(good_sample_index_limit), int(BATCH_SIZE-int(BATCH_SIZE*TERMINAL_BIAS)))\n",
    "        bad_sample_index  = np.random.choice(int(bad_sample_index_limit),  int(BATCH_SIZE*TERMINAL_BIAS))\n",
    "\n",
    "        b_good_memory = self.good_memory[good_sample_index, :]\n",
    "        b_bad_memory  = self.bad_memory[bad_sample_index, :]\n",
    "        b_memory      = np.vstack((b_good_memory,b_bad_memory))\n",
    "        \n",
    "        b_s  = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a  = torch.LongTensor( b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r  = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval   = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        a_eval   = self.eval_net(b_s).max(1)[1].view(BATCH_SIZE, 1) #best action according to eval_net\n",
    "        q_next   = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + NN_GAMMA * q_next.gather(1, a_eval)   # shape (batch, 1)\n",
    "        loss     = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(MIN_VAL, VAL, MAX_VAL):\n",
    "    return max(MIN_VAL, min(VAL, MAX_VAL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABSOLUTE LIMITS ON STATE VALUES\n",
    "C_POS_ABS_MAX =  2.4\n",
    "C_POS_ABS_MIN = -2.4\n",
    "\n",
    "C_VEL_ABS_MAX =  5\n",
    "C_VEL_ABS_MIN = -5\n",
    "\n",
    "P_ANG_ABS_MAX =  0.25\n",
    "P_ANG_ABS_MIN = -0.25\n",
    "\n",
    "P_VEL_ABS_MAX =  6\n",
    "P_VEL_ABS_MIN = -6\n",
    "\n",
    "LENGTH_ABS_MAX = 0.925\n",
    "LENGTH_ABS_MIN = 0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI_GRAIN =  40\n",
      "LO_GRAIN =  10\n"
     ]
    }
   ],
   "source": [
    "# SET GRANULARITY\n",
    "HI_GRAIN = 40\n",
    "LO_GRAIN = 10\n",
    "print(\"HI_GRAIN = \", HI_GRAIN)\n",
    "print(\"LO_GRAIN = \", LO_GRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_node_run(node_id, boundary, iteration, node_q_table):\n",
    "\n",
    "    # SET SEED\n",
    "    ###############################################\n",
    "    my_seed = seed + node_id + iteration\n",
    "    random.seed(my_seed)\n",
    "    torch.manual_seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "    my_env = env\n",
    "    my_env.seed(my_seed)\n",
    "    ###############################################\n",
    "    \n",
    "    # Mean values of pole length deviate from original value\n",
    "    scaling_factor = 0.8 + (1.8 - 0.8) * (node_id + 1)/(NO_OF_NODES)\n",
    "    ORIGNAL_LENGTH = 0.5    \n",
    "    length_mean    = ORIGNAL_LENGTH * scaling_factor\n",
    "\n",
    "    LENGTH_MAX = length_mean + 0.025\n",
    "    LENGTH_MIN = length_mean - 0.025\n",
    "\n",
    "    # CREATE STATE TABLE BORDERS\n",
    "    ###############################################\n",
    "    c_pos_s  = np.linspace(C_POS_ABS_MIN,  C_POS_ABS_MAX,  HI_GRAIN)\n",
    "    c_vel_s  = np.linspace(C_VEL_ABS_MIN,  C_VEL_ABS_MAX,  HI_GRAIN)\n",
    "    p_ang_s  = np.linspace(P_ANG_ABS_MIN,  P_ANG_ABS_MAX,  HI_GRAIN)\n",
    "    p_vel_s  = np.linspace(P_VEL_ABS_MIN,  P_VEL_ABS_MAX,  HI_GRAIN)\n",
    "    length_s = np.linspace(LENGTH_MIN,     LENGTH_MAX,     LO_GRAIN)\n",
    "\n",
    "    borders = [c_pos_s, c_vel_s, p_ang_s, p_vel_s, length_s]\n",
    "    ###############################################\n",
    "    \n",
    "    my_Q_TABLE = node_q_table[:,:,:,:, int(node_id*LO_GRAIN):int((node_id+1)*LO_GRAIN)]\n",
    "\n",
    "    time_rec                = np.zeros(NO_OF_EPISODES)\n",
    "    level_up_flag           = False\n",
    "    PERFECT_RUN_COUNTER     = 10\n",
    "    PERFECT_RUNS_HIGH_SCORE = 10\n",
    "    level_up_metric         = 195\n",
    "\n",
    "    exp_rec      = np.empty(N_STATES * 2 + 2)\n",
    "    \n",
    "#     if iteration < 3:\n",
    "#         my_EPSILON   = 0.9 + (iteration+1)*0.02 + np.random.uniform(-0.1,0.1)\n",
    "#     else:\n",
    "#         my_EPSILON   = T_EPSILON + np.random.uniform(-0.01,0.01)\n",
    "        \n",
    "    my_EPSILON = T_EPSILON\n",
    "        \n",
    "    my_LR        = T_LR\n",
    "    \n",
    "    while True:\n",
    "        i_episode = 0\n",
    "        \n",
    "        while i_episode < NO_OF_EPISODES:\n",
    "            ep_exp_rec = np.empty(N_STATES * 2 + 2)\n",
    "            time_steps = 0\n",
    "\n",
    "            my_env.length   = length_mean + np.random.uniform(-0.025,0.025)\n",
    "            xtra = [my_env.length]\n",
    "            \n",
    "            s = my_env.reset()\n",
    "            s = np.append(s, xtra)\n",
    "            \n",
    "            while True:\n",
    "                time_steps += 1\n",
    "                \n",
    "                #get state\n",
    "                this_state = tuple(discretize(s, borders))\n",
    "                \n",
    "                # choose action\n",
    "                if np.random.uniform() > my_EPSILON:   # greedy\n",
    "                    a = np.random.randint(0, N_ACTIONS)\n",
    "                else:\n",
    "                    a = my_Q_TABLE[this_state][:].argmax()\n",
    "\n",
    "                 # take action\n",
    "                s_, r, done, info = my_env.step(a)\n",
    "                s_ = np.append(s_, xtra)\n",
    "\n",
    "                if done:\n",
    "                    r = -1\n",
    "                    if time_steps >= TIMESTEP_LIMIT:\n",
    "                        r = 1\n",
    "                \n",
    "                #store experience\n",
    "                experience = np.hstack((s,a,r,s_))\n",
    "                exp_rec = np.vstack((exp_rec, experience))\n",
    "\n",
    "                #discretize next_state\n",
    "                next_state = tuple(discretize(s_, borders))\n",
    "\n",
    "                # learn\n",
    "#                 my_Q_TABLE[this_state][a] = my_Q_TABLE[this_state][a] + my_LR * (r + T_GAMMA * my_Q_TABLE[next_state].max() - my_Q_TABLE[this_state][a])\n",
    "                \n",
    "                if done or time_steps >= TIMESTEP_LIMIT:\n",
    "                    time_rec[i_episode] = time_steps\n",
    "                    break\n",
    "                s = s_\n",
    "\n",
    "            i_episode += 1\n",
    "        if i_episode >= NO_OF_EPISODES:\n",
    "            i_episode = 0\n",
    "            break\n",
    "\n",
    "    exp_rec = np.delete(exp_rec, 0, 0)\n",
    "#         message = \"NODE#\"+str(node_id) +\" MAIN Q:\"+ str(new_Q_TABLE.mean()) +\"\\t\" + \"NODE Q:\" + str(my_Q_TABLE.mean())\n",
    "#         print(message)\n",
    "    \n",
    "    # GET NEW STATE BOUNDARIES: +/- 25% of experienced state\n",
    "    [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX, LENGTH_MAX ] = [exp_rec[:,i].max() for i in range(N_STATES)]\n",
    "    [C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN, LENGTH_MIN ] = [exp_rec[:,i].min() for i in range(N_STATES)]\n",
    "\n",
    "    newboundary = [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX, LENGTH_MAX,\n",
    "                   C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN, LENGTH_MIN]\n",
    "    \n",
    "    return exp_rec, time_rec, newboundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_serial_timesteps   = 0\n",
    "total_parallel_timesteps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "# my_dqn = D3QN()\n",
    "dqn = D3QN()\n",
    "init_model = D3QN_prev();\n",
    "INIT_MODEL_FILENAME = './models/'+ 'perfect_init' + \".pt\"\n",
    "init_model.eval_net.load_state_dict(torch.load(INIT_MODEL_FILENAME));\n",
    "init_model.eval_net.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 1305.01 MiB, increment: 1085.09 MiB\n",
      "Quantization TIME:  0.01 minutes\n"
     ]
    }
   ],
   "source": [
    "# CREATE STATE COMBINATIONS\n",
    "# ###############################################\n",
    "\n",
    "old_init_state_combinations = ndim_grid([C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN],\n",
    "                                    [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX],\n",
    "                                    [HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GET Q-VALUES \n",
    "start = timeit.default_timer()\n",
    "%memit old_init_q_table = init_model.get_qvals(old_init_state_combinations).reshape(HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , -1).astype(np.float16)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Quantization TIME: \", np.round((stop-start)/60,2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new q_table by repeating old q_table\n",
    "init_q_table = np.repeat(old_init_q_table[:,:,:,:,np.newaxis,:],LO_GRAIN*NO_OF_NODES,axis=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE BOUNDARY TO MAXIMUM VALUES\n",
    "init_node_boundary = [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX, LENGTH_ABS_MAX,\n",
    "                      C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN, LENGTH_ABS_MIN]\n",
    "\n",
    "\n",
    "\n",
    "# CREATE STATE COMBINATIONS\n",
    "# ###############################################\n",
    "\n",
    "init_state_combinations = ndim_grid([C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN, LENGTH_ABS_MIN ],\n",
    "                                    [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX, LENGTH_ABS_MAX ],\n",
    "                                    [HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN*NO_OF_NODES   ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GET Q-VALUES \n",
    "# start = timeit.default_timer()\n",
    "# %memit init_q_table = dqn.get_qvals(init_state_combinations).reshape(HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN*NO_OF_NODES , -1).astype(np.float16)\n",
    "# stop = timeit.default_timer()\n",
    "# print(\"Quantization TIME: \", np.round((stop-start)/60,2), \"minutes\")\n",
    "    \n",
    "# SAVE QFILE\n",
    "# node_QFILE = './Q_NPY/' + RNDM_STRING + 'QFILE' + \".npy\"\n",
    "# np.save(node_QFILE, init_q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENVIRONMENT FOR CHECKING NN MODEL\n",
    "v_env = gym.make('CartPole-v0')\n",
    "v_env.seed(seed*2)\n",
    "\n",
    "# CREATE A POOL OF PROCESSES\n",
    "pool = mp.Pool(NO_OF_NODES)\n",
    "\n",
    "# SET INITIAL NODE BOUDNARIES FOR ALL NODES\n",
    "node_boundaries = [init_node_boundary] * NO_OF_NODES\n",
    "node_q_table = init_q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION # 0\n",
      "MEAN TABULAR EPSILON =  0.2\n",
      "TABULAR LR      =  0.01\n",
      "SMALLEST TIMESTEP in ITERATION 0: 200\n",
      "REAL TIME TO GENERATE 400000 EXPERIENCES:0:00:49.950793\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while iteration < MAX_NO_OF_ITERATIONS:\n",
    "    if iteration < 3:\n",
    "        node_EPSILON   = (iteration+1) * 0.2\n",
    "    else:\n",
    "        node_EPSILON   = T_EPSILON\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"ITERATION #\", iteration)\n",
    "    print(\"MEAN TABULAR EPSILON = \", node_EPSILON)\n",
    "    print(\"TABULAR LR      = \", T_LR)\n",
    "\n",
    "    tic = datetime.now()\n",
    "    \n",
    "    # MAP GYM ENVIRONMENT TO EACH PROCESS IN THE POOL\n",
    "    ##################################################################\n",
    "    q_table_list = [node_q_table]* NO_OF_NODES\n",
    "    iter_list = [iteration] * NO_OF_NODES\n",
    "    arg_list = [arg for arg in zip(range(NO_OF_NODES), node_boundaries, iter_list, q_table_list)]\n",
    "    result   = pool.starmap(mp_node_run, arg_list)\n",
    "    ##################################################################\n",
    "    \n",
    "    # GATHER RESULTS\n",
    "    ##################################################################\n",
    "    node_boundaries = np.array([item[2] for item in result])\n",
    "    node_time_rec   = np.array([item[1] for item in result])\n",
    "    node_exp        = np.array([item[0] for item in result])\n",
    "    \n",
    "    all_exp         = np.array([item for each_node_exp in node_exp \n",
    "                                    for episode_exp in each_node_exp \n",
    "                                    for item in episode_exp]).reshape(-1,N_STATES*2+2)\n",
    "    total_parallel_timesteps += node_time_rec.max()\n",
    "    total_serial_timesteps   += node_time_rec.sum()\n",
    "    EXP_GEN = node_time_rec.sum().astype(int)\n",
    "\n",
    "    print(\"SMALLEST TIMESTEP in ITERATION {:d}: {:d}\".format(iteration, node_time_rec.min().astype(int)))\n",
    "    print(\"REAL TIME TO GENERATE {:d} EXPERIENCES:{}\".format(EXP_GEN, (datetime.now()-tic)))\n",
    "    ##################################################################\n",
    "\n",
    "    # PLOT EXPERIENCES\n",
    "    ##################################################################\n",
    "    node_avg_time = node_time_rec.mean(axis=1)\n",
    "    node_std_time = node_time_rec.std(axis=1)\n",
    "    node_max_time = node_time_rec.max(axis=1)\n",
    "    node_min_time = node_time_rec.min(axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize = (15,3))\n",
    "    ax2 = fig.add_subplot(1, 1, 1)\n",
    "    ax2.set_title(\"Q-table Performance\")\n",
    "    ax2.bar(range(NO_OF_NODES) , node_max_time, alpha = 0.1, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "    ax2.bar(range(NO_OF_NODES) , node_avg_time, alpha = 0.5, color = 'g', edgecolor = 'black', capsize=7 )\n",
    "    ax2.bar(range(NO_OF_NODES) , node_min_time, alpha = 0.4, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "\n",
    "    ax2.plot(np.ones_like(node_avg_time)*200, 'g--')\n",
    "    ax2.set_ylabel('Mean Node Lifetime',color = 'g')\n",
    "    ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "    fig.tight_layout()\n",
    "    ax2.grid()\n",
    "    plt.show()\n",
    "    ##################################################################\n",
    "    \n",
    "    if node_min_time.min() > 195:\n",
    "        final_result = \"SUCCESS\"\n",
    "        break\n",
    "\n",
    "    # SEGREGATE AND STORE EXPERIENCES\n",
    "    ##################################################################\n",
    "    good_mem = all_exp[all_exp[:,N_STATES+1] == 1]    \n",
    "    bad_mem  = all_exp[all_exp[:,N_STATES+1] < 1]\n",
    "\n",
    "\n",
    "    dqn.good_memory = np.insert(dqn.good_memory, 0, good_mem , 0)\n",
    "    dqn.good_memory_counter += good_mem.shape[0]\n",
    "\n",
    "    dqn.bad_memory  = np.insert(dqn.bad_memory, 0, bad_mem , 0)\n",
    "    dqn.bad_memory_counter += bad_mem.shape[0]\n",
    "\n",
    "    dqn.good_memory = dqn.good_memory[:MIN_MEMORY_CAP,:]\n",
    "    dqn.bad_memory = dqn.bad_memory[:MIN_MEMORY_CAP,:]\n",
    "\n",
    "    NN_ITERATIONS = MAX_NN_ITERATIONS\n",
    "\n",
    "    print(\"GOOD MEMORY COUNTER: \", min(MIN_MEMORY_CAP, dqn.good_memory_counter))\n",
    "    print(\"BAD MEMORY COUNTER: \", min(MIN_MEMORY_CAP, dqn.bad_memory_counter))\n",
    "    ##################################################################\n",
    "\n",
    "    # LEARN\n",
    "    ##################################################################\n",
    "    if iteration < 3:\n",
    "        NN_LR = 1e-4\n",
    "    else:\n",
    "        NN_LR = 1e-3\n",
    "    print(\"Training Neural Network for\", NN_ITERATIONS, \"iterations\", \"@ LR = \", NN_LR)\n",
    "    print(int(BATCH_SIZE*TERMINAL_BIAS),\"TERMINAL EXPERIENCES IN A BATCH SIZE OF\",BATCH_SIZE)\n",
    "    tic=datetime.now()\n",
    "    nn_level_up_metric = 0\n",
    "    for nn_iter in range(NN_ITERATIONS):\n",
    "        dqn.learn()\n",
    "        #validate by running for TIMESTEP_LIMIT iterations\n",
    "        if(nn_iter%int(NN_ITERATIONS/5) == int(NN_ITERATIONS/5)-1):\n",
    "            print(\"Validating... \",end=\"\")\n",
    "            time_rec = []\n",
    "            v_env.length   = np.random.uniform(LENGTH_ABS_MIN, LENGTH_ABS_MAX)\n",
    "            v_xtra = [v_env.length]\n",
    "            for i_episode in range(TIMESTEP_LIMIT):\n",
    "                time_step = 0\n",
    "                s = v_env.reset()\n",
    "                s = np.append(s, v_xtra)\n",
    "\n",
    "                while True:\n",
    "                    time_step += 1 \n",
    "                    a = dqn.choose_greedy_action(s)\n",
    "                    s_, r, done, info = v_env.step(a)\n",
    "                    s_ = np.append(s_, v_xtra)\n",
    "\n",
    "                    if done:\n",
    "                        break\n",
    "                    s = s_\n",
    "                time_rec = np.append(time_rec, time_step)\n",
    "            mean_time = time_rec.mean()\n",
    "            print(\"MEAN TIME: \", mean_time)\n",
    "            if mean_time >= nn_level_up_metric:\n",
    "                nn_level_up_metric = mean_time\n",
    "                torch.save(dqn.eval_net.state_dict(), MODEL_FILENAME)\n",
    "\n",
    "    print(\"TRAINING TIME:{}\".format(datetime.now()-tic))\n",
    "    ##################################################################\n",
    "\n",
    "    # CHECK PERFORMANCE OF THE BEST MODEL\n",
    "    ##################################################################\n",
    "    best_dqn = D3QN()\n",
    "    best_dqn.eval_net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    best_dqn.eval_net.eval()\n",
    "\n",
    "    time_rec = []\n",
    "    for i_episode in range(TIMESTEP_LIMIT):\n",
    "        env.length   = np.random.uniform(LENGTH_ABS_MIN, LENGTH_ABS_MAX)\n",
    "        Xtra = [env.length]\n",
    "        time_step = 0\n",
    "        s = env.reset()\n",
    "        s = np.append(s, Xtra)\n",
    "\n",
    "        while True:\n",
    "    #         env.render()\n",
    "            time_step += 1 \n",
    "            a = best_dqn.choose_greedy_action(s)\n",
    "            s_, r, done, info = env.step(a)\n",
    "            s_ = np.append(s_, Xtra)\n",
    "            if done:\n",
    "                break\n",
    "            s = s_\n",
    "        time_rec = np.append(time_rec, time_step)\n",
    "\n",
    "    fig = plt.figure(figsize = (15,3))\n",
    "    ax2 = fig.add_subplot(1, 1, 1)\n",
    "    data = time_rec\n",
    "    ax2.plot(data, color = 'm')\n",
    "    ax2.plot(np.ones_like(data)*200, 'm--')\n",
    "    ax2.set_title('Neural Network Performance using BEST MODEL ')\n",
    "    ax2.set_ylabel('Time Steps',color = 'm')\n",
    "    ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "    fig.tight_layout()\n",
    "    ax2.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "        \n",
    "    ##################################################################\n",
    "    \n",
    "    # CREATE ONE LARGE Q-TABLES FROM WHICH THE NODES STRIP\n",
    "    ##################################################################\n",
    "        \n",
    "#     node_state_combinations = ndim_grid([C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN, LENGTH_ABS_MIN ],\n",
    "#                                         [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX, LENGTH_ABS_MAX ],\n",
    "#                                         [HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN * NO_OF_NODES  ])\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    # GET Q-VALUES \n",
    "    %memit node_q_table = best_dqn.get_qvals(init_state_combinations).reshape(HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN*NO_OF_NODES , -1).astype(np.float16)\n",
    "\n",
    "    # SAVE QFILE\n",
    "#     np.save(node_QFILE, node_q_table)\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "#     ##################################################################\n",
    "    \n",
    "#     # CREATE INDIVIDUALIZED Q-TABLES FOR THE NODES\n",
    "#     ##################################################################\n",
    "    \n",
    "#     for node_id in range(NO_OF_NODES):\n",
    "# #         # SET STATE VALUE BORDERS AS REQUESTED BY THE NODE\n",
    "# #         ###############################################\n",
    "#         [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX, LENGTH_MAX,\n",
    "#          C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN, LENGTH_MIN]  = node_boundaries[node_id]\n",
    "# #         ###############################################\n",
    "#         print(node_id,'-max-',node_boundaries[node_id][:N_STATES])\n",
    "#         print(node_id,'-min-',node_boundaries[node_id][N_STATES:])\n",
    "#         print(\"\")\n",
    "        \n",
    "# #         node_boundaries[node_id] = [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX, LENGTH_MAX,\n",
    "# #                                     C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN, LENGTH_MIN]\n",
    "# #         # CREATE STATE COMBINATIONS\n",
    "# #         ###############################################\n",
    "\n",
    "#     node_state_combinations = ndim_grid([C_POS_ABS_MIN, C_VEL_ABS_MIN, P_ANG_ABS_MIN, P_VEL_ABS_MIN, LENGTH_ABS_MIN ],\n",
    "#                                         [C_POS_ABS_MAX, C_VEL_ABS_MAX, P_ANG_ABS_MAX, P_VEL_ABS_MAX, LENGTH_ABS_MAX ],\n",
    "#                                         [HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN   ])\n",
    "#         ###############################################\n",
    "#     start = timeit.default_timer()\n",
    "#     # GET Q-VALUES \n",
    "#     %memit node_q_table = best_dqn.get_qvals(node_state_combinations).reshape(HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN , -1).astype(np.float16)\n",
    "\n",
    "#     # SAVE QFILE\n",
    "#     np.save(node_QFILE, node_q_table)\n",
    "#         #############################################################################################################################################\n",
    "#     stop = timeit.default_timer()\n",
    "    print(\"Quantization TIME: \", np.round((stop-start)/60,2), \"minutes\")\n",
    "    iteration += 1\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parallel Timesteps :  200.0\n",
      "Total Serial Timesteps   :  400000.0\n",
      "Speed-up                 :  2000.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Parallel Timesteps : \", total_parallel_timesteps)\n",
    "print(\"Total Serial Timesteps   : \", total_serial_timesteps)\n",
    "print(\"Speed-up                 :  {:6.2f}\".format(total_serial_timesteps/total_parallel_timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()\n",
    "if iteration == MAX_NO_OF_ITERATIONS:\n",
    "    final_result = \"FAILURE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9295 SUCCESS 200   0     200     400000    2000.00\n"
     ]
    }
   ],
   "source": [
    "print(\"{:6d} {} {:3d} {:3d} {:7d} {:10d} {:10.2f}\".format(seed, final_result, int(node_min_time.min()), int(iteration), int(total_parallel_timesteps), int(total_serial_timesteps), total_serial_timesteps/total_parallel_timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
